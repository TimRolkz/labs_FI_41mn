{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6285a63-e584-4a41-b711-a7144edcf5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "932acb2c-703d-4a8a-831b-f9c9309cfccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Типи даних:\n",
      " Year                               float64\n",
      "Status                              object\n",
      "Adult Mortality                    float64\n",
      "infant deaths                      float64\n",
      "Alcohol                            float64\n",
      "percentage expenditure             float64\n",
      "Hepatitis B                        float64\n",
      "Measles                            float64\n",
      " BMI                               float64\n",
      "under-five deaths                  float64\n",
      "Polio                              float64\n",
      "Total expenditure                  float64\n",
      "Diphtheria                         float64\n",
      " HIV/AIDS                          float64\n",
      "GDP                                float64\n",
      "Population                         float64\n",
      " thinness  1-19 years              float64\n",
      " thinness 5-9 years                float64\n",
      "Income composition of resources    float64\n",
      "Schooling                          float64\n",
      "dtype: object\n",
      "Категоріальні колонки:\n",
      " Index(['Status'], dtype='object')\n",
      "Розмір після кодування: (2938, 20)\n",
      "Epoch 10/1000, Loss: 4056.6213\n",
      "Epoch 20/1000, Loss: 983.7335\n",
      "Epoch 30/1000, Loss: 481.2363\n",
      "Epoch 40/1000, Loss: 224.6431\n",
      "Epoch 50/1000, Loss: 121.5956\n",
      "Epoch 60/1000, Loss: 87.6545\n",
      "Epoch 70/1000, Loss: 78.2583\n",
      "Epoch 80/1000, Loss: 70.1501\n",
      "Epoch 90/1000, Loss: 63.5671\n",
      "Epoch 100/1000, Loss: 58.9617\n",
      "Epoch 110/1000, Loss: 55.0094\n",
      "Epoch 120/1000, Loss: 51.8951\n",
      "Epoch 130/1000, Loss: 49.1859\n",
      "Epoch 140/1000, Loss: 46.7725\n",
      "Epoch 150/1000, Loss: 44.5965\n",
      "Epoch 160/1000, Loss: 42.5763\n",
      "Epoch 170/1000, Loss: 40.7103\n",
      "Epoch 180/1000, Loss: 38.9647\n",
      "Epoch 190/1000, Loss: 37.3077\n",
      "Epoch 200/1000, Loss: 35.7254\n",
      "Epoch 210/1000, Loss: 34.2171\n",
      "Epoch 220/1000, Loss: 32.7843\n",
      "Epoch 230/1000, Loss: 31.3972\n",
      "Epoch 240/1000, Loss: 30.0685\n",
      "Epoch 250/1000, Loss: 28.8014\n",
      "Epoch 260/1000, Loss: 27.5897\n",
      "Epoch 270/1000, Loss: 26.4167\n",
      "Epoch 280/1000, Loss: 25.2811\n",
      "Epoch 290/1000, Loss: 24.1713\n",
      "Epoch 300/1000, Loss: 23.0966\n",
      "Epoch 310/1000, Loss: 22.0520\n",
      "Epoch 320/1000, Loss: 21.0671\n",
      "Epoch 330/1000, Loss: 20.1473\n",
      "Epoch 340/1000, Loss: 19.2863\n",
      "Epoch 350/1000, Loss: 18.4969\n",
      "Epoch 360/1000, Loss: 17.7683\n",
      "Epoch 370/1000, Loss: 17.0930\n",
      "Epoch 380/1000, Loss: 16.4583\n",
      "Epoch 390/1000, Loss: 15.8663\n",
      "Epoch 400/1000, Loss: 15.3287\n",
      "Epoch 410/1000, Loss: 14.8373\n",
      "Epoch 420/1000, Loss: 14.3847\n",
      "Epoch 430/1000, Loss: 13.9648\n",
      "Epoch 440/1000, Loss: 13.5727\n",
      "Epoch 450/1000, Loss: 13.2074\n",
      "Epoch 460/1000, Loss: 12.8620\n",
      "Epoch 470/1000, Loss: 12.5325\n",
      "Epoch 480/1000, Loss: 12.2159\n",
      "Epoch 490/1000, Loss: 11.9144\n",
      "Epoch 500/1000, Loss: 11.6358\n",
      "Epoch 510/1000, Loss: 11.3798\n",
      "Epoch 520/1000, Loss: 11.1429\n",
      "Epoch 530/1000, Loss: 10.9212\n",
      "Epoch 540/1000, Loss: 10.7170\n",
      "Epoch 550/1000, Loss: 10.5281\n",
      "Epoch 560/1000, Loss: 10.3534\n",
      "Epoch 570/1000, Loss: 10.1971\n",
      "Epoch 580/1000, Loss: 10.0536\n",
      "Epoch 590/1000, Loss: 9.9211\n",
      "Epoch 600/1000, Loss: 9.8018\n",
      "Epoch 610/1000, Loss: 9.6908\n",
      "Epoch 620/1000, Loss: 9.5888\n",
      "Epoch 630/1000, Loss: 9.4950\n",
      "Epoch 640/1000, Loss: 9.4068\n",
      "Epoch 650/1000, Loss: 9.3225\n",
      "Epoch 660/1000, Loss: 9.2406\n",
      "Epoch 670/1000, Loss: 9.1619\n",
      "Epoch 680/1000, Loss: 9.0862\n",
      "Epoch 690/1000, Loss: 9.0118\n",
      "Epoch 700/1000, Loss: 8.9402\n",
      "Epoch 710/1000, Loss: 8.8698\n",
      "Epoch 720/1000, Loss: 8.8001\n",
      "Epoch 730/1000, Loss: 8.7342\n",
      "Epoch 740/1000, Loss: 8.6746\n",
      "Epoch 750/1000, Loss: 8.6190\n",
      "Epoch 760/1000, Loss: 8.5656\n",
      "Epoch 770/1000, Loss: 8.5145\n",
      "Epoch 780/1000, Loss: 8.4653\n",
      "Epoch 790/1000, Loss: 8.4193\n",
      "Epoch 800/1000, Loss: 8.3759\n",
      "Epoch 810/1000, Loss: 8.3348\n",
      "Epoch 820/1000, Loss: 8.2950\n",
      "Epoch 830/1000, Loss: 8.2576\n",
      "Epoch 840/1000, Loss: 8.2224\n",
      "Epoch 850/1000, Loss: 8.1894\n",
      "Epoch 860/1000, Loss: 8.1575\n",
      "Epoch 870/1000, Loss: 8.1266\n",
      "Epoch 880/1000, Loss: 8.0960\n",
      "Epoch 890/1000, Loss: 8.0665\n",
      "Epoch 900/1000, Loss: 8.0388\n",
      "Epoch 910/1000, Loss: 8.0133\n",
      "Epoch 920/1000, Loss: 7.9888\n",
      "Epoch 930/1000, Loss: 7.9655\n",
      "Epoch 940/1000, Loss: 7.9436\n",
      "Epoch 950/1000, Loss: 7.9223\n",
      "Epoch 960/1000, Loss: 7.9006\n",
      "Epoch 970/1000, Loss: 7.8793\n",
      "Epoch 980/1000, Loss: 7.8589\n",
      "Epoch 990/1000, Loss: 7.8393\n",
      "Epoch 1000/1000, Loss: 7.8199\n",
      "Test Loss: 8.2931\n",
      "Test R^2 Score: 0.9043\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Завантаження датасету\n",
    "df = pd.read_csv(\"Life Expectancy Data.csv\")\n",
    "\n",
    "# Видалення рядків із пропусками\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer=SimpleImputer(missing_values=np.nan,strategy='mean',fill_value=None)\n",
    "df_nan = df.isnull().sum()\n",
    "list_col_to_fill = list(df_nan[df_nan > 0].index)\n",
    "for cl_n in list_col_to_fill:\n",
    "    df[cl_n] = imputer.fit_transform(df[[cl_n]])\n",
    "\n",
    "# Вибір ознак (X) і цільової змінної (y)\n",
    "# Наприклад, прогнозуємо тривалість життя\n",
    "X = df.drop(columns=[\"Life expectancy \", \"Country\"])\n",
    "y = df[\"Life expectancy \"]\n",
    "\n",
    "# Масштабування числових ознак\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Вибір числових колонок\n",
    "numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Нормалізація\n",
    "scaler = StandardScaler()\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "# Перевірка типів даних\n",
    "print(\"Типи даних:\\n\", X.dtypes)\n",
    "\n",
    "# Визначення категоріальних колонок\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "print(\"Категоріальні колонки:\\n\", categorical_columns)\n",
    "\n",
    "# Кодування категоріальних колонок\n",
    "X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
    "X['Status_Developing'] = X['Status_Developing'].astype(int)\n",
    "print(\"Розмір після кодування:\", X.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Розділення на тренувальні та тестові дані\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Перетворення в тензори PyTorch\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)  # Додаємо .values\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float32)    # Додаємо .values\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Архітектура повнозв'язаної нейронної мережі\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Ініціалізація моделі\n",
    "input_dim = X_train.shape[1]\n",
    "model = FeedForwardNN(input_dim)\n",
    "\n",
    "# Вибір оптимізатора та функції втрат\n",
    "criterion = nn.MSELoss()  # Оскільки це регресійна задача\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Навчання моделі\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Прогноз\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "\n",
    "    # Оновлення ваг\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# Оцінка моделі\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(X_test)\n",
    "    test_loss = criterion(y_pred_test, y_test)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Оцінка моделі\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(X_test).numpy()  # Передбачення для тестових даних\n",
    "    y_test_numpy = y_test.numpy()  # Перетворення тестових значень у numpy\n",
    "\n",
    "    # Розрахунок R^2\n",
    "    r2 = r2_score(y_test_numpy, y_pred_test)\n",
    "    print(f\"Test R^2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa681688-0960-4931-b4b6-e538ed2c4a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b09af6e6-f9aa-451b-b789-7e96b3df54d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класи в датасеті: ['jerry', 'tom']\n",
      "Кількість класів: 2, Класи: ['jerry', 'tom']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Шлях до папки з даними\n",
    "data_path = \"tom_and_jerry_dataset\"\n",
    "\n",
    "# Перевірка структури датасету\n",
    "print(\"Класи в датасеті:\", os.listdir(data_path))\n",
    "\n",
    "# Підготовка трансформацій\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Зміна розміру зображень\n",
    "    transforms.ToTensor(),  # Перетворення в тензор\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Нормалізація\n",
    "])\n",
    "\n",
    "# Завантаження даних\n",
    "dataset = ImageFolder(root=data_path, transform=transform)\n",
    "\n",
    "# Розділення даних на тренувальні та тестові\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Завантаження в DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Перевірка класів\n",
    "print(f\"Кількість класів: {len(dataset.classes)}, Класи: {dataset.classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc140944-49a2-4f75-a9d2-53aa6c3bbab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Архітектура CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Ініціалізація моделі\n",
    "num_classes = len(dataset.classes)\n",
    "model = CNN(num_classes)\n",
    "\n",
    "# Навчання моделі\n",
    "# Використовуйте попередній код навчання\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4951554-508c-4ee5-82ae-14bee68e57a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.2803\n",
      "Epoch 2/5, Loss: 0.2819\n",
      "Epoch 3/5, Loss: 0.2627\n",
      "Epoch 4/5, Loss: 0.1255\n",
      "Epoch 5/5, Loss: 0.0208\n",
      "Accuracy (from scratch): 0.9416\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Функція втрат і оптимізатор\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Навчання моделі\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# Оцінка моделі\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predicted.numpy())\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy (from scratch): {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee8551b3-c8b0-4071-9c10-a3cdfce6b5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "# Завантаження попередньо натренованої моделі\n",
    "model = resnet18(pretrained=True)\n",
    "\n",
    "# Оновлення вихідного шару\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Freeze попередні шари\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc.weight.requires_grad = True\n",
    "model.fc.bias.requires_grad = True\n",
    "\n",
    "# Навчання моделі\n",
    "# Використовуйте попередній код навчання\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18da009c-fdb2-4922-8656-dcab9acfc7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.3962\n",
      "Epoch 2/5, Loss: 0.5417\n",
      "Epoch 3/5, Loss: 0.1416\n",
      "Epoch 4/5, Loss: 0.2747\n",
      "Epoch 5/5, Loss: 0.2024\n",
      "Accuracy (transfer learning): 0.8675\n"
     ]
    }
   ],
   "source": [
    "# Функція втрат і оптимізатор\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Навчання моделі\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# Оцінка моделі\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predicted.numpy())\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy (transfer learning): {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7c9fca9-d9b1-4212-a6a0-26c09366b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b253030-3663-4b89-9d0b-7bb3a0bb4d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  films adapted from comic books have had plenty...  positive\n",
      "1  every now and then a movie comes along from a ...  positive\n",
      "2  you've got mail works alot better than it dese...  positive\n",
      "3   \" jaws \" is a rare film that grabs your atten...  positive\n",
      "4  moviemaking is a lot like being the general ma...  positive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Вкажіть шлях до папки з датасетом\n",
    "dataset_path = r\"review_polarity\\txt_sentoken\"\n",
    "\n",
    "# Завантаження позитивних і негативних відгуків\n",
    "pos_reviews = []\n",
    "neg_reviews = []\n",
    "\n",
    "# Читання файлів із позитивними відгуками\n",
    "for filename in os.listdir(os.path.join(dataset_path, \"pos\")):\n",
    "    with open(os.path.join(dataset_path, \"pos\", filename), \"r\", encoding=\"utf-8\") as file:\n",
    "        pos_reviews.append(file.read())\n",
    "\n",
    "# Читання файлів із негативними відгуками\n",
    "for filename in os.listdir(os.path.join(dataset_path, \"neg\")):\n",
    "    with open(os.path.join(dataset_path, \"neg\", filename), \"r\", encoding=\"utf-8\") as file:\n",
    "        neg_reviews.append(file.read())\n",
    "\n",
    "# Формування датасету\n",
    "reviews = pos_reviews + neg_reviews\n",
    "labels = [\"positive\"] * len(pos_reviews) + [\"negative\"] * len(neg_reviews)\n",
    "\n",
    "df = pd.DataFrame({\"review\": reviews, \"sentiment\": labels})\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8348370-d11f-4f1e-a3c4-50fc3e36d682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment  \\\n",
      "0  films adapted from comic books have had plenty...  positive   \n",
      "1  every now and then a movie comes along from a ...  positive   \n",
      "2  you've got mail works alot better than it dese...  positive   \n",
      "3   \" jaws \" is a rare film that grabs your atten...  positive   \n",
      "4  moviemaking is a lot like being the general ma...  positive   \n",
      "\n",
      "                                      cleaned_review  \n",
      "0  films adapted comic books plenty success wheth...  \n",
      "1  every movie comes along suspect studio every i...  \n",
      "2  got mail works alot better deserves order make...  \n",
      "3  jaws rare film grabs attention shows single im...  \n",
      "4  moviemaking lot like general manager nfl team ...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Стоп-слова\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Функція для очищення тексту\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # До нижнього регістру\n",
    "    text = re.sub(r'\\W', ' ', text)  # Видалення пунктуації\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Видалення зайвих пробілів\n",
    "    tokens = word_tokenize(text)  # Токенізація\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]  # Видалення стоп-слів\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Передобробка текстів\n",
    "df[\"cleaned_review\"] = df[\"review\"].apply(preprocess_text)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccee028f-3548-4ab5-94c8-08aeb36b4508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Векторизація текстів\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Обмеження кількості ознак\n",
    "X = vectorizer.fit_transform(df[\"cleaned_review\"])\n",
    "y = df[\"sentiment\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b261629c-55e8-4629-8da9-62891e625ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кількість класів: ['negative' 'positive']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Розподіл на тренувальну і тестову вибірки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Преобразування міток класів\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "print(\"Кількість класів:\", label_encoder.classes_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "090e4e43-a9f0-4bb6-9450-f6c11171bec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchtext\\__init__.py:7: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  \"\\n/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \\n\"\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tokenizer\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_vocab_from_iterator\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequence\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchtext\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m     _WARN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     20\u001b[0m _TEXT_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/models/text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m _CACHE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_get_torch_home(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchtext\\_extension.py:64\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[43m_init_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchtext\\_extension.py:58\u001b[0m, in \u001b[0;36m_init_extension\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mod_utils\u001b[38;5;241m.\u001b[39mis_module_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext._torchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext C++ Extension is not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibtorchtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchtext\\_extension.py:50\u001b[0m, in \u001b[0;36m_load_lib\u001b[1;34m(lib)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\_ops.py:1350\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1345\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[0;32m   1348\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[0;32m   1349\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[1;32m-> 1350\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2288.0_x64__qbz5n2kfra8p0\\Lib\\ctypes\\__init__.py:379\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] The specified procedure could not be found"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "# Побудова словника\n",
    "tokenizer = get_tokenizer(language='ukr')\n",
    "def yield_tokens(data_iter):\n",
    "    for tokens in data_iter:\n",
    "        yield tokens\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(X_train), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# Перетворення текстів на індекси\n",
    "def text_pipeline(tokens):\n",
    "    return vocab(tokens)\n",
    "\n",
    "# Приведення текстів до одного розміру\n",
    "def collate_batch(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    texts = [torch.tensor(text_pipeline(tokens), dtype=torch.long) for tokens in texts]\n",
    "    texts = pad_sequence(texts, batch_first=True, padding_value=0)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return texts, labels\n",
    "\n",
    "# Підготовка датасету\n",
    "train_data = list(zip(X_train, y_train))\n",
    "test_data = list(zip(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da22c22d-b3f7-47d1-8bf9-6bff182e1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177871c-c3f8-4975-b12e-6d0f1c98f273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
